{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "2e898969-21f4-44a5-b5f3-3315eb3fdc54"
    }
   },
   "source": [
    "## Preprocessing the Frongoch Farm Magnetometer Data\n",
    "\n",
    "The magnetometer data is stored on an smb server with the following folder structure:\n",
    "![The magnetometer data](mag_file_struct.png)\n",
    "All data recorded before 2014 is stored in the folder ``2013``. The data in this folder is stored in ``.CSV`` files (in capitals), one ``.CSV`` file for each day. Data from 2014 onwards is stored in a folder, labelled the year it's recorded. (n.b. At the time of writing this, the folders only go up to 2018.)\n",
    "Each ``.csv`` file contains 3 columns; the time of the recording (timestamp), reading (a number from 0 to 65534) and temperature (in celsius). The first task, will be to combine these daily ``.csv``s into yearly ``.csv``s.\n",
    "\n",
    "``.csv`` files created before 2014 only have the hour, minute and second in their timestamp.\n",
    "``.csv``s from 2014 onwards have a LabView timestamp, which is a number representing the number of seconds elapsed since $00:00:00, 1^{st} January, 1904$ (LabView zerotime, see http://www.ni.com/tutorial/7900/en/). To covert this timestamp to a python (or numpy) datetime object, the timestamp needs converting to POSIX time. This can be done by adding the value of LabView zerotime in POSIX time, to the LabView timestamps.\n",
    "\n",
    "1. Import the relevant libs, and set the value of LabView zerotime in POSIX time. Also, set the path where the .csv's are stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "63f98126-4ad9-4357-b446-201257ce5995"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "%matplotlib inline\n",
    "\n",
    "# Set the location of the magnetometer .csv data files smb mount/ copy of the smb mount.\n",
    "# (the '/' are necessary!)\n",
    "dat_fp = \"../mag_data_copy/\"\n",
    "# Set the filepath the save the .csvs to.\n",
    "save_fp = \"csvs/\"\n",
    "\n",
    "# Get the National instruments (LabView) zero time in unix time.\n",
    "NI_zerotime = np.datetime64('1904-01-01T00:00:00.000Z').astype('datetime64[s]').astype(np.float64)\n",
    "# Print the value of LabView zerotime in UNIX zero time.\n",
    "print(\"LV_zerotime in UNIX zerotime is:\", NI_zerotime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "4811802c-5d86-4835-a89a-1d262b50fa60"
    }
   },
   "source": [
    "2. Load daily ``.csv``s from 2014 to 2018 and save them as yearly ``.csv``s. Different years are loaded into separate pandas dataframes. The LabView timestamps will be converted into POSIX datetimes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "c22f240c-4652-47f3-a3e3-d7a4b6bbdc69"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def load_data(folder):\n",
    "    \"\"\"Load the .csv's for a given year folder into a pandas dataframe.\"\"\"\n",
    "    # Initial list of dataframes, one dataframe for each csv (which will be combined later).\n",
    "    dataframes = []\n",
    "    \n",
    "    # Walk through the folder to find .csvs.\n",
    "    for root, dirs, files in os.walk(folder):\n",
    "        for file in files:\n",
    "            try:\n",
    "                # Try reading the csv into a pandas dataframe, with the expected\n",
    "                # columns: time, reading, temperature.\n",
    "                day_dat = pd.read_csv(os.path.join(root, file),\n",
    "                                      names=(\"time\", \"reading\", \"temperature\"),\n",
    "                                    dtype={\"time\": np.float64, \"reading\": np.float64, \"temperature\": np.float64})\n",
    "            except Exception as e:\n",
    "                # Print what could not be loaded and why.\n",
    "                print(\"Could not load:\", os.path.join(root, file))\n",
    "                print(e)\n",
    "            else:\n",
    "                # Convert the LabView timestamps into POSIX timestamps, then load as datetimes.\n",
    "                day_dat[\"time\"] = pd.to_datetime(day_dat[\"time\"] + NI_zerotime, unit='s')\n",
    "                dataframes.append(day_dat)\n",
    "    \n",
    "    # Combine the dataframes for each .csv (daily dataframes) into a single dataframe.\n",
    "    sensor_dat = pd.concat(dataframes, ignore_index=True)\n",
    "    # Sort data by time.\n",
    "    sensor_dat.sort_values(\"time\", inplace=True)\n",
    "    # Set the timestamps as the dataframe index.\n",
    "    sensor_dat.set_index(\"time\", drop=True, inplace=True)\n",
    "    return sensor_dat\n",
    "\n",
    "\n",
    "# Load the magnetometer data from 2014 to 2018.\n",
    "for year_data in [\"2014\", \"2015\", \"2016\", \"2017\", \"2018\"]:\n",
    "    # Load the data for a given year. The data for a given year is\n",
    "    # stored in \"/path/to/mag/data/\"+year e.g. \"../mag_dat/2014/\"\n",
    "    sensor_dat = load_data(dat_fp+year_data)\n",
    "    # Save the loaded year of data to a new csv, which will contain a whole year of data.\n",
    "    # This is stored in \"/path/to/mag/data/\"+year+\"mag_dat.csv\" e.g. \"./csvs/2014_mag_dat.csv\"\n",
    "    sensor_dat.to_csv(save_fp+year_data+\"_mag_dat.csv\", index=True)\n",
    "    # Display the head of the sensor data.\n",
    "    print(\"\\n\" + year_data + \" Data\")\n",
    "    display(sensor_dat.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Load the data from before 2014.\n",
    "\n",
    "This is more complex than loading the data from after 2014, because the readings are not accompanied with proper timestamps. Some examples of timestamps are given below:\n",
    "\n",
    "```\n",
    "5\n",
    "347\n",
    "155869\n",
    "```\n",
    "\n",
    "These timestamps would correspond to the following times:\n",
    "\n",
    "```\n",
    "00:00:05\n",
    "00:03:47\n",
    "15:58:69\n",
    "```\n",
    "\n",
    "To make reading these timestamps easier, the python string method `str.zfill()` can be used to pad out these timestamps. e.g. `\"5\".zfill(6)` returns `\"000005\"`, `\"347\".zfill(6)` returns `\"000347\"`. Another tricky problem, is that the timestamps recorded during BST are shifted 1 hour, so 1 hour needs subtracting from these times to shift them back to GMT/ UTC.\n",
    "\n",
    "To get the day, month and year for the timestamp, the modification time of the ``.csv``s (when the ``.csv`` was written) can be used. It will be assumed that the file modification time is the day after the readings were taken, so 1 day will need subtracting from the generated timestamps.\n",
    "\n",
    "Sometimes the last reading in the ``.CSV`` file is actually recorded the day after the other sensor readings. In this case, 1 day is added to the sensor reading timestamp.\n",
    "\n",
    "Set the start and end of BST for 2011, 2012 and 2013:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "27026623-d36d-447f-a3cf-f0dfb17b754c"
    }
   },
   "outputs": [],
   "source": [
    "# Manually set when the BST hour changes occur.\n",
    "hour_change_2011 = {\"start\": datetime(year=2011, month=3, day=27, hour=1, minute=0, second=0), \"end\": datetime(year=2011, month=10, day=30, hour=2, minute=0, second=0)}\n",
    "hour_change_2012 = {\"start\": datetime(year=2012, month=3, day=25, hour=1, minute=0, second=0), \"end\": datetime(year=2012, month=10, day=28, hour=2, minute=0, second=0)}\n",
    "hour_change_2013 = {\"start\": datetime(year=2013, month=3, day=31, hour=1, minute=0, second=0), \"end\": datetime(year=2013, month=10, day=27, hour=2, minute=0, second=0)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the pre-2014 data. This will also save all the from before 2014 into a ``.csv`` file called `pre2014_mag_dat.csv`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "8a552443-f05b-404f-8147-b6f17b78af9c"
    }
   },
   "outputs": [],
   "source": [
    "def load_2013_dat():\n",
    "    \"\"\"Load the .CSV's from before 2014, at the filepath dat_fp.\"\"\"\n",
    "    dataframes = []\n",
    "    \n",
    "    # Walk through all the files created before 2013.\n",
    "    for root, dirs, files in os.walk(dat_fp+\"2013\"):\n",
    "        print(\"Files loaded:\")\n",
    "        for file in files:\n",
    "            # Check whether the file being loaded is a csv file (upper or lowercase .csv name).\n",
    "            if file.lower().endswith(\".csv\"):\n",
    "                try:\n",
    "                    file = os.path.join(root, file)\n",
    "                    # Retrieve file modification time. This will be used to get\n",
    "                    # the year, month and day of the recording.\n",
    "                    date = datetime.fromtimestamp(os.path.getmtime(file))\n",
    "                    day_dat = pd.read_csv(file, names=(\"time\", \"reading\", \"temperature\"))\n",
    "                    print(file)\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                else:\n",
    "                    # First, set the time to an integer, then to a string.\n",
    "                    day_dat[\"time\"] = day_dat[\"time\"].astype('int').astype(\"str\", copy=False)\n",
    "                    # Make sure all strings are 6 characters long, filled with zeros\n",
    "                    day_dat[\"time\"] = day_dat[\"time\"].apply(lambda dt : dt.zfill(6))\n",
    "                    # Convert strings to datetimes, formatted as \"%H%M%S\".\n",
    "                    day_dat[\"time\"] = pd.to_datetime(day_dat[\"time\"], format=\"%H%M%S\")\n",
    "                    # Include the current year, day, month in the datetimes, as retrieved from the file modification time.\n",
    "                    day_dat[\"time\"] = day_dat[\"time\"].apply(lambda dt: dt.replace(year=date.year, month=date.month, day=date.day))\n",
    "                    # Due to an error, the last recording in the csv's is for the next day.\n",
    "                    # The error can be verified by checking whether the last time is\n",
    "                    # earlier than the previous.\n",
    "                    # We need a try-except because the csv may only contain 1 item.\n",
    "                    try:\n",
    "                        if day_dat.iloc[-1, 0] < day_dat.iloc[-2, 0]:\n",
    "                            # if the last time is earlier than the previous, then add a day to the time.\n",
    "                            day_dat.iloc[-1, 0] += timedelta(days=1)\n",
    "                    except IndexError:\n",
    "                        print(\"Warning! Only 1 reading in the csv!\")\n",
    "                        \n",
    "                    dataframes.append(day_dat)\n",
    "\n",
    "    sensor_dat = pd.concat(dataframes, ignore_index=True)\n",
    "    # Readings were taken in GMT and BST. Make them all GMT (UTC).\n",
    "    # Find BST times.\n",
    "    BST_mask = ((sensor_dat[\"time\"] >= hour_change_2011[\"start\"]) & (sensor_dat[\"time\"] < hour_change_2011[\"end\"]))\n",
    "    BST_mask |= ((sensor_dat[\"time\"] >= hour_change_2012[\"start\"]) & (sensor_dat[\"time\"] < hour_change_2012[\"end\"]))\n",
    "    BST_mask |= ((sensor_dat[\"time\"] >= hour_change_2013[\"start\"]) & (sensor_dat[\"time\"] < hour_change_2013[\"end\"]))\n",
    "    print(sensor_dat.shape, BST_mask.shape)\n",
    "    # Subtract an hour from the bst times\n",
    "    sensor_dat.loc[BST_mask, \"time\"] -= timedelta(hours=1)\n",
    "    # Subtract 1 day from each timestamp, as the modification time of the file\n",
    "    # is actually the day after the sensor readings are taken.\n",
    "    sensor_dat[\"time\"] -= timedelta(days=1)\n",
    "    # Set the timestamps as the index.\n",
    "    sensor_dat.set_index(\"time\", inplace=True)\n",
    "    \n",
    "    return sensor_dat\n",
    "\n",
    "# Load the pre-2014 magnetometer data.\n",
    "sensor_dat = load_2013_dat()\n",
    "# Save pre-2014 data to a csv.\n",
    "sensor_dat.to_csv(save_fp+\"pre2014_mag_dat.csv\")\n",
    "# Display the first 5 rows of data.\n",
    "sensor_dat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Save the pre-2014 data into yearly ``.csv``s.\n",
    "\n",
    "Load the data recorded before 2014 into the csv file `pre2014_mag_dat.csv`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "189b3874-3e5d-4691-a562-c89692d24eee"
    }
   },
   "outputs": [],
   "source": [
    "sensor_dat = pd.read_csv(save_fp+\"pre2014_mag_dat.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the string timestamps into datetimes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "76ea8288-134a-427c-889b-067fb08d349b"
    }
   },
   "outputs": [],
   "source": [
    "sensor_dat[\"time\"] = pd.to_datetime(sensor_dat[\"time\"], format=\"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data by year and save to separate csvs called `year+\"mag_dat.csv\"` e.g. `2013_mag_dat.csv`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "35f22847-f2a9-4757-8952-6df8cdcb532f"
    }
   },
   "outputs": [],
   "source": [
    "sensor_dat_yearsplit = {}\n",
    "for year in sensor_dat[\"time\"].dt.year.unique():\n",
    "    sensor_dat_yearsplit[str(year)] = sensor_dat.loc[sensor_dat[\"time\"].dt.year == year]\n",
    "    sensor_dat_yearsplit[str(year)].to_csv(save_fp+str(year)+\"_mag_dat.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Check what some of this sensor data looks like when plotted (note this is **raw** data, not magnetic readings):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "33237814-c53a-4879-a991-9db36413e17a"
    }
   },
   "outputs": [],
   "source": [
    "sensor_dat = sensor_dat.loc[sensor_dat[\"reading\"] < 0.6e7]\n",
    "sensor_dat.plot(x=\"time\", y=\"reading\", figsize=(15,5))\n",
    "\n",
    "# plt.savefig(\"test.pdf\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:mag_srv_env]",
   "language": "python",
   "name": "conda-env-mag_srv_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
